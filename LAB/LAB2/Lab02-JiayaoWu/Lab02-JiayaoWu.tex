\documentclass[12pt,a4paper]{article}
%\usepackage{ctex}
\usepackage{amsmath,amscd,amsbsy,amssymb,latexsym,url,bm,amsthm}
\usepackage{epsfig,graphicx,subfigure}
\usepackage{enumitem,balance}
\usepackage{wrapfig}
\usepackage{mathrsfs,euscript}
\usepackage[x11names,svgnames,dvipsnames]{xcolor}
\usepackage{hyperref}
\usepackage[vlined,ruled,commentsnumbered,linesnumbered]{algorithm2e}
\usepackage{listings}
\usepackage{multicol}
%\usepackage{fontspec}

\renewcommand{\listalgorithmcfname}{List of Algorithms}
\renewcommand{\algorithmcfname}{Alg.}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{exercise}{Exercise}
\newtheorem*{solution}{Solution}
\newtheorem{definition}{Definition}
\theoremstyle{definition}


%\numberwithin{equation}{section}
%\numberwithin{figure}{section}

\renewcommand{\thefootnote}{\fnsymbol{footnote}}

\newcommand{\postscript}[2]
 {\setlength{\epsfxsize}{#2\hsize}
  \centerline{\epsfbox{#1}}}

\renewcommand{\baselinestretch}{1.0}

\setlength{\oddsidemargin}{-0.365in}
\setlength{\evensidemargin}{-0.365in}
\setlength{\topmargin}{-0.3in}
\setlength{\headheight}{0in}
\setlength{\headsep}{0in}
\setlength{\textheight}{10.1in}
\setlength{\textwidth}{7in}
\makeatletter \renewenvironment{proof}[1][Proof] {\par\pushQED{\qed}\normalfont\topsep6\p@\@plus6\p@\relax\trivlist\item[\hskip\labelsep\bfseries#1\@addpunct{.}]\ignorespaces}{\popQED\endtrivlist\@endpefalse} \makeatother
\makeatletter
\renewenvironment{solution}[1][Solution] {\par\pushQED{\qed}\normalfont\topsep6\p@\@plus6\p@\relax\trivlist\item[\hskip\labelsep\bfseries#1\@addpunct{.}]\ignorespaces}{\popQED\endtrivlist\@endpefalse} \makeatother


\definecolor{codegreen}{rgb}{0.44,0.68,0.28}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.96,0.96,0.96}

\lstset{
language=C++,
frame=shadowbox,
keywordstyle = \color{blue}\bfseries,
commentstyle=\color{codegreen},
tabsize = 4,
backgroundcolor=\color{backcolour},
numbers=left,
numbersep=5pt,
breaklines=true,
emph = {int,float,double,char},emphstyle=\color{orange},
emph ={[2]const, typedef},emphstyle = {[2]\color{red}} }



\begin{document}
\noindent

%========================================================================
\noindent\framebox[\linewidth]{\shortstack[c]{
\Large{\textbf{Lab02-Sorting and Searching}}\vspace{1mm}\\
VE281 - Data Structures and Algorithms, Xiaofeng Gao, TA: Li Ma, Autumn 2019}}
%CS26019 - Algorithm Design and Analysis, Xiaofeng Gao, Autumn 2019}}
\begin{center}
\footnotesize{\color{red}$*$ Please upload your assignment to website. Contact webmaster for any questions.}

\footnotesize{\color{blue}$*$ Name:Wu Jiayao  \quad Student ID:517370910257 \quad Email: jiayaowu1999@sjtu.edu.cn}
\end{center}


\begin{enumerate}

\item \textbf{Cocktail Sort.} Consider the pseudo code of a sorting algorithm shown in Alg.~\ref{Alg-Cocktail}, which is called \emph{Cocktail Sort}, then answer the following questions.


\begin{minipage}[t]{0.4\textwidth}
\begin{enumerate}
\item What is the minimum number of element comparisons performed by the algorithm? When is this minimum achieved?
\item What is the maximum number of element comparisons performed by the algorithm? When is this maximum achieved?
\item Express the running time of the algorithm in terms of the $O$ notation.
\item Can the running time of the algorithm be expressed in terms of the $\Theta$ notation? Explain.
\end{enumerate}
\end{minipage}
\hspace{2mm}
\begin{minipage}[t]{0.5\textwidth}
\begin{algorithm}[H]
		\caption{CocktailSort($a$[$\cdot$], $n$)} \label{Alg-Cocktail}
		\KwIn {an array $a$, the length of array $n$}
		\For {$i=0; i<n-1; i++$}
		{
			$bFlag \leftarrow true$;
			
			\For {$j=i;j<n-i-1;j++$}
			{
				\If {$a[j]>a[j+1]$}
				{
					swap($a[j]$, $a[j+1]$)\;
					$bFlag \leftarrow false$;
				}
			}
			
			\If {bFlag}
			{
				break;
			}
			
			$bFlag \leftarrow true$;			
			
			\For {$j=n-i-1;j>i;j--$}
			{
				\If {$a[j]<a[j-1]$}
				{
					swap($a[j]$, $a[j-1]$)\;
					$bFlag \leftarrow false$;
				}
			}
			\If {bFlag}
			{
				break;
			}
		}
\end{algorithm}
\end{minipage}

%\end{multicols}
\begin{solution}
	: \\
	(a)The minimum number is $n-1$
	$$
	n-0-1-0 = n-1
	$$. 
	It is achieved when the array is already sorted. \\
	(b)The maximum number is $\frac{n^2}{2}-(n \% 2)\cdot \frac{1}{2}$. 
	\begin{align*}
		\sum_{i=0}^{\lfloor \frac{n-1}{2} \rfloor} 2 \times (n-i-1-i) &= \sum_{i=0}^{\lfloor \frac{n-1}{2} \rfloor} 2 \times (n-2i-1) \\ 
		& = \frac{n^2}{2}-(n \% 2)\cdot \frac{1}{2}
	\end{align*}
	It is achieved when the array is sorted from the biggest to the smallest number. \\
	(c) $O(n^2)$ \\
	(d) No. The best case is $O(n)$ and the worst case is $O(n^2)$. Hence, neither $\Theta(n)$ nor $\Theta(n^2)$ can express the running time.
\end{solution}

\item \textbf{In-Place.} In place means an algorithm requires $O(1)$ additional memory, including the stack space used in recursive calls. Frankly speaking, even for a same algorithm, different implementation methods bring different in-place characteristics. Taking \emph{Binary Search} as an example, we give two kinds of implementation pseudo codes shown in Alg.~\ref{Alg-RecursiveBS} and Alg.~\ref{Alg-NonRecursiveBS}. Please analyze whether they are in place.
    
    Next, please give one similar example regarding other algorithms you know to illustrate such phenomenon.

\item  \textbf{Master Theorem}.

\begin{definition}[Matrix Multiplication]
The product of two $n \times n$ matrices $X$ and $Y$ is a third $n \times n$ matrix $Z = XY$, with $(i,j)$th entry
$$Z_{ij}=\sum_{k=1}^{n}X_{ik}Y_{kj}.$$
\end{definition}
$Z_{ij}$ is the dot product of the $i$th row of $X$ with $j$th column of $Y$. The preceding formula implies an $O(n^3)$ algorithm for matrix multiplication.

\begin{minipage}[t]{0.49\textwidth}
\begin{algorithm}[H]
	\BlankLine
	\SetKwInOut{Input}{Input}
	\SetKwInOut{Output}{Output}
	\caption{BinSearch($a[\cdot]$, $x$, $low$, $high$)} 
	\label{Alg-RecursiveBS}
	\Input{a sorted array $a$ of $n$ elements, an integer $x$, first index $low$, last index $high$}
	\Output{first index of key $x$ in $a$, $-1$ if not found}
	\BlankLine
	\If{$high < low$}{
	\Return{-1};
	}
    $mid \leftarrow low +((high - low) / 2)$;
    
    
    \uIf{$a[mid] > x$}{
	$mid \leftarrow$ {$\text{BinSearch}(a,x,low, mid - 1)$};
	}
    \uElseIf{$a[mid] < x$}{
    $mid \leftarrow$ {$\text{BinSearch}(a,x,mid+1, high)$};
    }
   \Else {
    \Return{$mid$};
    }
\end{algorithm}
\end{minipage}
\begin{minipage}[t]{0.455\textwidth}
\begin{algorithm}[H]
\BlankLine
	\SetKwInOut{Input}{input}
	\SetKwInOut{Output}{output}
	\caption{BinSearch($a[\cdot]$, $x$, $low$, $high$)} \label{Alg-NonRecursiveBS}
	\Input{a sorted array $a$ of $n$ elements, an integer $x$, first index $low$, last index $high$}	\Output{first index of key $x$ in $a$, $-1$ if not found}
	\BlankLine	
	\While{$low \leq high$}{
	$mid \leftarrow low + ((high - low) / 2)$;
	
	\uIf{$a[mid] > x$}
	{
		$high \leftarrow mid - 1$;
	}
	\uElseIf{$a[mid] < x$}{
	    $low \leftarrow mid + 1$;
	}
	\Else{
	    \Return{$mid$};
	}
	}
	\Return{-1};
\end{algorithm}\end{minipage}
\begin{solution}
	Alg.~\ref{Alg-RecursiveBS} is not in place. For each recursive step, there will be $O(1)$ additional memory for temp variable $mid$. As there are $O(\log n)$ recursive steps, the additional memory is $O(\log n)$. \\
	Alg.~\ref{Alg-NonRecursiveBS} is in place. Only $O(1)$ additional memory is required for temp variable $mid$. \\
	Example: \\
	The merge sort we learn in class, which takes $O(n)$ additional memory, is not in place.
	Here is another implementation of merge sort. \\
	\begin{algorithm}[H]
		\BlankLine
        \SetKwInOut{Input}{input}
        \SetKwInOut{Output}{output}
    	\caption{MergeSort($a[\cdot]$,$left$,$right$)} \label{merge}
    	\Input{An array $a$ of $n$ elements,the most $left$ and most $right$ index of the part to sort}
    	\Output{a sorted array a}
    	\BlankLine
    	\If{left \textbf{$\geq$} right}{
    	    \textbf{return}
		}
		MergeSort($a[\cdot]$,$left$,$n/2$) \\
		MergeSort($a[\cdot]$,$n/2+1$,$right$) \\
		i $\gets $ $left$ \\
		j $\gets$ $n/2+1$ \\
		tmp $\gets$ j \\
		\While{i $\textless$ right}{
		\While{a[i] $\textbf{\textless}$ a[j]}{i++}
		\While{a[i] $\textbf{\textgreater}$ a[j]}{j++}
		swap \textbf{a[i:index]} with \textbf{a[index:j]} \\
		$i$ $\gets$ $i+j-tmp$}
	\end{algorithm}
	Only 3 additional variable is used. This MergeSort is in place.
\end{solution}



In 1969, the German mathematician Volker Strassen announced a siginificantly more efficient algorithm, based upon divide-and-conquer. Matrix Multiplication can be performed blockwise. To see what this means, carve $X$ into four $\frac{n}{2} \times \frac{n}{2}$ blocks, and also $Y$:
\begin{displaymath}
X=
\left(\begin{array}{c|c}
A & B \\
\hline
C & D \end{array}\right), \quad
Y=\left(\begin{array}{c|c}
E & F \\
\hline
G & H \end{array}\right).
 \end{displaymath}

Then their product can be expressed in terms of these blocks and is exactly as if the blocks were single elements.

 \begin{displaymath}
 XY=
\left(\begin{array}{c|c}
A & B \\
\hline
C & D \end{array}\right)
\left(\begin{array}{c|c}
E & F \\
\hline
G & H \end{array}\right)
=
\left(\begin{array}{c|c}
AE+BG & AF+BH \\
\hline
CE+DG & CF+DH \end{array}\right).
 \end{displaymath}

To compute the size-$n$ product $XY$, recursively compute eight size-$\frac{n}{2}$ products $AE$,  $BG$, $AF$, $BH$, $CE$, $DG$, $CF$, $DH$ and then do a few additions.

\begin{enumerate}
\item Write down the recurrence function of the above method and compute its running time by Master Theorem.

\begin{solution}
	$f(n) = 8f(\frac{n}{2})+4=f(n) = 8f(\frac{n}{2})+O(1)$. The running time is $O(n^{\log_{2}{8}})=O(n^3)$.
\end{solution}

\item The efficiency can be further improved. It turns out $XY$ can be computed from just seven $\frac{n}{2}\times \frac{n}{2}$ subproblems.

\begin{displaymath}
 XY=
\left(\begin{array}{c|c}
P_{5}+P_{4}-P_{2}+P_{6} & P_{1}+P_{2} \\
\hline
P_{3}+P_{4} & P_{1}+P_{5}-P_{3}-P_{7} \end{array}\right),
\end{displaymath}
where
\begin{align*}
P_{1}&=A(F-H), \qquad P_{2}=(A+B)H, \qquad P_{3}=(C+D)E, \qquad P_{4}=D(G-E),\\
P_{5}&=(A+D)(E+H),\qquad P_{6}=(B-D)(G+H),\qquad P_{7}=(A-C)(E+H).
\end{align*}

Write the corresponding recurrence function and compute the new running time.
\begin{solution}
	$f(n) = 7f(\frac{n}{2})+8=f(n) = 7f(\frac{n}{2})+O(1)$. The running time is $O^{\log_{2}{7}}$.
\end{solution}

\end{enumerate}


\end{enumerate}

%========================================================================
\end{document}
